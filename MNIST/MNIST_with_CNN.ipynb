{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from keras\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of train and test data set\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correct label is 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN/klEQVR4nO3de4xc9XnG8efxBRMMJDZgWLC5JW4pQhToiktBDZWVlBAlBlqiEJUShWZRG1CoohJEKkEvimjaQFALVKbQGEQhkRKEVdESy3VCSMBloQZMTAKlBgxbG2RaLgHjtd/+sYd2Y3Z+s8w5c7Hf70dazcx5z+XVwONzZn4z83NECMDub0a/GwDQG4QdSIKwA0kQdiAJwg4kMauXB9vDc2JPze3lIYFU3tIbeju2eqparbDbPkPSdZJmSvr7iLi6tP6emquTvKTOIQEUrIlVLWsdX8bbninpekkfk3S0pPNsH93p/gB0V53X7CdKejoinomItyXdKWlpM20BaFqdsB8i6flJjzdWy36B7RHbo7ZHt2lrjcMBqKNO2Kd6E+Bdn72NiGURMRwRw7M1p8bhANRRJ+wbJS2a9HihpBfrtQOgW+qE/SFJi20fYXsPSZ+WtKKZtgA0reOht4gYt32xpHs1MfR2S0Q80VhnABpVa5w9Iu6RdE9DvQDoIj4uCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii1pTNtjdIek3SdknjETHcRFMAmlcr7JXfjIiXG9gPgC7iMh5Iom7YQ9L3bD9se2SqFWyP2B61PbpNW2seDkCn6l7GnxoRL9peIGml7Scj4r7JK0TEMknLJGlfz4+axwPQoVpn9oh4sbrdLOkuSSc20RSA5nUcdttzbe/zzn1JH5W0rqnGADSrzmX8gZLusv3Ofv4xIv6lka7wnrzy2VNa1v7tqzcWtz3q/vOL9cM+9XhHPWHwdBz2iHhG0q822AuALmLoDUiCsANJEHYgCcIOJEHYgSSa+CIMuuzn55xUrK/8i2ta1rbFHsVtP3z408X6hmIVuxLO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsA2DWIQcX67902RPF+l4uj6WXPHj78cX6Qfpxx/uuy7PK/3u+dvavFes7Ptf6d1A3P3lAcdsP/dGDxfquiDM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsAeGt5+T/D3y36Qcf7/pPN5bHohSteKNbHOz5yfdtPPqZY//43buh43+fv+5Fi/ZWO9zy4OLMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs/fArCMPL9ZHDv3XWvt/fcfWlrV1n1xY3Hb8+WdrHbudGcce1bL25CX7FLddvuSmpttJre2Z3fYttjfbXjdp2XzbK20/Vd3O626bAOqazmX8NyWdsdOyyyWtiojFklZVjwEMsLZhj4j7JG3ZafFSScur+8slndVsWwCa1ukbdAdGxJgkVbcLWq1oe8T2qO3RbWr92hJAd3X93fiIWBYRwxExPFtzun04AC10GvZNtockqbrd3FxLALqh07CvkHRBdf8CSXc30w6Abmk7zm77DkmnS9rf9kZJV0q6WtK3bV8o6TlJ53azyV3dzy4aKtY/Obfet6ev3PThlrXx5zfW2nc7M45pPY4uSb/zre+3rP3evuXv0tf1cOEtokfvLfd9aB9/L79b2oY9Is5rUVrScC8AuoiPywJJEHYgCcIOJEHYgSQIO5AEX3FtwMzFRxbrf37WnV09/j89cELL2i/v+Whx25c/U56yeemlq4v1kXk3F+vzZuxZrHfTZ+7/fMva4j/b/YbW2uHMDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM7egLeOmF+s//beL3f1+D89pzB18Tnttv5RzaP3bxx9W2wv1vdbzS8jTcaZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9AbPeGC/Wx7a/WawPzXxfk+00alOb3ke3HlSsf3yv/+n42O3G0Y+565JiffE/PNDxsXdHnNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2RvgH60t1pd+7bJi/aI/LE9vf+H7nyvWd2hHy9rFG08vbvuD1ccW6wf/sPwZgpc+9/Ni/eMn31qsl4xtf7tYX3zJmo73nVHbM7vtW2xvtr1u0rKrbL9ge231d2Z32wRQ13Qu478p6Ywpll8bEcdVf/c02xaAprUNe0TcJ2lLD3oB0EV13qC72PZj1WX+vFYr2R6xPWp7dJu21jgcgDo6DfuNkj4o6ThJY5K+3mrFiFgWEcMRMTxb/AAg0C8dhT0iNkXE9ojYIekmSSc22xaApnUUdttDkx6eLWldq3UBDAZHRHkF+w5Jp0vaX9ImSVdWj4+TFJI2SLooIsbaHWxfz4+TvKROv7ulWYsWFutvHDtUrBeG2TXnnx/qoKNJuz7tuGL9+tuvL9aPmNX578oftfr3i/UP/e6/d7zv3dWaWKVXY4unqrX9UE1EnDfF4ptrdwWgp/i4LJAEYQeSIOxAEoQdSIKwA0nwFdcBMP78xmJ9Tpt6N71wafkrrnWG1v7mlcXF+lFfKU91Xe4MO+PMDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM6e3OaLf71Yv++kv2qzh87H2W+7YarfMf1/C579ccf7xrtxZgeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn383NGjqoWD93ZFWx/v4ZnY+jS9IJ37ikZe3gGx+otW+8N5zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtl3A569R8vaKfduKG77x/v9pNaxN21/s1hfuPK/W9Z2tJkuHM1qe2a3vcj2atvrbT9h+4vV8vm2V9p+qrqd1/12AXRqOpfx45K+FBG/IulkSV+wfbSkyyWtiojFklZVjwEMqLZhj4ixiHikuv+apPWSDpG0VNLyarXlks7qUo8AGvCe3qCzfbik4yWtkXRgRIxJE/8gSFrQYpsR26O2R7dpa812AXRq2mG3vbek70i6NCJene52EbEsIoYjYni25nTSI4AGTCvstmdrIui3R8R3q8WbbA9V9SFJm7vTIoAmtB16s21JN0taHxHXTCqtkHSBpKur27u70iHamnHkoS1rX97vW7X2vXG8PLR2zl9eVqwvWMvPQQ+K6YyznyrpfEmP215bLbtCEyH/tu0LJT0n6dyudAigEW3DHhH3S3KL8pJm2wHQLXxcFkiCsANJEHYgCcIOJEHYgST4iutu4Ok/3atr+/7qf/1Wsb7gBsbRdxWc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZdwEvj5xSrK897bpCdWZx2/8cf6tYf+xvjy3WPyCmXd5VcGYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ98FvHlAqx/3nTDb5bH0kk88+AfF+uG3MY6+u+DMDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJTGd+9kWSbpV0kKQdkpZFxHW2r5L0eUkvVateERH3dKvRzA67dm2xPnZR6znUh2a+r+FusKuazodqxiV9KSIesb2PpIdtr6xq10bEX3evPQBNmc787GOSxqr7r9leL+mQbjcGoFnv6TW77cMlHS9pTbXoYtuP2b7F9rwW24zYHrU9uk1b63ULoGPTDrvtvSV9R9KlEfGqpBslfVDScZo48399qu0iYllEDEfE8GzNqd8xgI5MK+y2Z2si6LdHxHclKSI2RcT2iNgh6SZJJ3avTQB1tQ27bUu6WdL6iLhm0vKhSaudLWld8+0BaIojoryCfZqkH0p6XBNDb5J0haTzNHEJH5I2SLqoejOvpX09P07yknodA2hpTazSq7Flyu9ET+fd+PslTbUxY+rALoRP0AFJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Jo+332Rg9mvyTp2UmL9pf0cs8aeG8GtbdB7Uuit0412dthEXHAVIWehv1dB7dHI2K4bw0UDGpvg9qXRG+d6lVvXMYDSRB2IIl+h31Zn49fMqi9DWpfEr11qie99fU1O4De6feZHUCPEHYgib6E3fYZtn9q+2nbl/ejh1Zsb7D9uO21tkf73MsttjfbXjdp2XzbK20/Vd1OOcden3q7yvYL1XO31vaZfeptke3VttfbfsL2F6vlfX3uCn315Hnr+Wt22zMl/UzSRyRtlPSQpPMi4ic9baQF2xskDUdE3z+AYfs3JL0u6daIOKZa9jVJWyLi6uofynkR8eUB6e0qSa/3exrvaraiocnTjEs6S9Jn1cfnrtDXp9SD560fZ/YTJT0dEc9ExNuS7pS0tA99DLyIuE/Slp0WL5W0vLq/XBP/s/Rci94GQkSMRcQj1f3XJL0zzXhfn7tCXz3Rj7AfIun5SY83arDmew9J37P9sO2RfjczhQPfmWarul3Q53521nYa717aaZrxgXnuOpn+vK5+hH2qqaQGafzv1Ig4QdLHJH2hulzF9ExrGu9emWKa8YHQ6fTndfUj7BslLZr0eKGkF/vQx5Qi4sXqdrOkuzR4U1FvemcG3ep2c5/7+T+DNI33VNOMawCeu35Of96PsD8kabHtI2zvIenTklb0oY93sT23euNEtudK+qgGbyrqFZIuqO5fIOnuPvbyCwZlGu9W04yrz89d36c/j4ie/0k6UxPvyP+HpK/0o4cWfR0p6dHq74l+9ybpDk1c1m3TxBXRhZL2k7RK0lPV7fwB6u02TUzt/ZgmgjXUp95O08RLw8ckra3+zuz3c1foqyfPGx+XBZLgE3RAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMT/Ap9/HyeeT1b+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print random image from training set\n",
    "import random\n",
    "num = random.randint(0, len(x_train))\n",
    "plt.imshow(x_train[num])\n",
    "print(f\"The correct label is {y_train[num]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to add a channel dimension when using convolutional layer\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model architecture\n",
    "shape = (28, 28, 1)\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=shape),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "     # Add the output layer with 10 units (one for each digit from 0-9)\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 91s 49ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0448 - val_accuracy: 0.9878\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 111s 59ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0474 - val_accuracy: 0.9879\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0596 - val_accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e62c5e44c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0596 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0595799945294857, 0.9889000058174133]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
